{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "!pip install opencv-python  # L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdWXPRr3JwOv",
        "outputId": "e5fa164d-3576-4eb7-cfdc-64265922f706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe.  # T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPV0_Po4JwUf",
        "outputId": "6944de11-5ee3-4592-de42-daf192fd8c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "cap = cv2.VideoCapture(2)  # 0기본 캠 -> 0-3까지 시도 실패함 !\n",
        "\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"없\")\n",
        "else:\n",
        "    print(\"열림\")\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# 웹캠이 열렸는지 확인\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUbRXR81L_Pd",
        "outputId": "f25c36d8-8713-4fe8-fc99-1e1420a2b4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "없\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python. # S"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q19RBH5rL_Rj",
        "outputId": "fd0fca26-74c4-4628-b031-bdbe2fbdd931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python mediapipe  # F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTTumO_JLJZH",
        "outputId": "c80b0b88-ce3c-4407-ebed-1d7744906416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Posture 없음\n",
        "#\n",
        "# import cv2\n",
        "# import mediapipe as mp\n",
        "# import numpy as np\n",
        "# import base64\n",
        "# from io import BytesIO\n",
        "# from PIL import Image\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# from google.colab.output import eval_js\n",
        "# from IPython.display import display, Javascript\n",
        "\n",
        "# # JavaScript로 웹캠 시작하기\n",
        "# def start_video_stream():\n",
        "#     display(Javascript('''\n",
        "#         async function startVideo() {\n",
        "#             const video = document.createElement('video');\n",
        "#             video.width = 640;\n",
        "#             video.height = 480;\n",
        "#             video.style.display = 'block';\n",
        "#             document.body.append(video);\n",
        "\n",
        "#             const stream = await navigator.mediaDevices.getUserMedia({\n",
        "#                 video: true\n",
        "#             });\n",
        "#             video.srcObject = stream;\n",
        "\n",
        "#             await new Promise((resolve) => {\n",
        "#                 video.onloadedmetadata = () => { resolve(video); };\n",
        "#             });\n",
        "\n",
        "#             video.play();\n",
        "#             window.video = video;\n",
        "#         }\n",
        "#         startVideo();\n",
        "#     '''))\n",
        "\n",
        "# # 비디오 프레임을 가져오는 함수 (수정된 방식)\n",
        "# def video_frame():\n",
        "#     js = eval_js('''\n",
        "#         const video = document.querySelector('video');\n",
        "#         const canvas = document.createElement('canvas');\n",
        "#         canvas.width = video.videoWidth;\n",
        "#         canvas.height = video.videoHeight;\n",
        "#         const context = canvas.getContext('2d');\n",
        "#         context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "#         // base64 이미지 데이터를 window 객체에 저장\n",
        "#         window.canvasData = canvas.toDataURL('image/png');\n",
        "#     ''')\n",
        "#     # JavaScript에서 저장한 데이터를 Python에서 가져옴\n",
        "#     return eval_js('window.canvasData')\n",
        "\n",
        "# # JavaScript 응답을 OpenCV 이미지로 변환\n",
        "# def js_to_image(js_reply):\n",
        "#     # base64 문자열에서 'data:image/png;base64,' 부분을 제거\n",
        "#     img_str = js_reply.split(',')[1]\n",
        "#     try:\n",
        "#         img_data = base64.b64decode(img_str)  # base64 디코딩\n",
        "#         img = Image.open(BytesIO(img_data))  # PIL 이미지로 변환\n",
        "#         img = np.array(img)  # NumPy 배열로 변환\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # OpenCV에서 사용할 수 있게 BGR로 변환\n",
        "#         return img\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error decoding image: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # MediaPipe 초기화\n",
        "# mp_pose = mp.solutions.pose\n",
        "# pose = mp_pose.Pose()\n",
        "\n",
        "# # 허리 각도를 계산하는 함수\n",
        "# def calculate_angle(hip, knee, shoulder):\n",
        "#     # 벡터 계산 (벡터는 각 관절 사이의 방향을 나타냄)\n",
        "#     vector1 = np.array([hip.x - knee.x, hip.y - knee.y])\n",
        "#     vector2 = np.array([shoulder.x - knee.x, shoulder.y - knee.y])\n",
        "\n",
        "#     # 두 벡터 간의 각도 계산 (단위: 라디안)\n",
        "#     dot_product = np.dot(vector1, vector2)\n",
        "#     magnitude1 = np.linalg.norm(vector1)\n",
        "#     magnitude2 = np.linalg.norm(vector2)\n",
        "#     angle_rad = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
        "#     angle_deg = np.degrees(angle_rad)\n",
        "#     return angle_deg\n",
        "\n",
        "# # 비디오 스트리밍 시작\n",
        "# start_video_stream()\n",
        "\n",
        "# # 비디오 처리\n",
        "# while True:\n",
        "#     # JavaScript로부터 비디오 프레임 받기\n",
        "#     js_reply = video_frame()\n",
        "#     if not js_reply:\n",
        "#         break\n",
        "\n",
        "#     # 프레임을 OpenCV 이미지로 변환\n",
        "#     img = js_to_image(js_reply)\n",
        "#     if img is None:\n",
        "#         continue  # 이미지가 없으면 건너뛰기\n",
        "\n",
        "#     # MediaPipe Pose로 사람의 자세 추적\n",
        "#     results = pose.process(img)\n",
        "\n",
        "#     if results.pose_landmarks:\n",
        "#         # 랜드마크 추출\n",
        "#         landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "#         # 각 관절의 좌표\n",
        "#         # 왼쪽 엉덩이, 왼쪽 무릎, 왼쪽 어깨\n",
        "#         left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "#         left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE]\n",
        "#         left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "\n",
        "#         # 오른쪽 엉덩이, 오른쪽 무릎, 오른쪽 어깨\n",
        "#         right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "#         right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE]\n",
        "#         right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "\n",
        "#         # 왼쪽과 오른쪽 허리 각도 계산\n",
        "#         left_angle = calculate_angle(left_hip, left_knee, left_shoulder)\n",
        "#         right_angle = calculate_angle(right_hip, right_knee, right_shoulder)\n",
        "\n",
        "#         # 각도를 텍스트로 화면에 출력\n",
        "#         cv2.putText(img, f\"Left Hip Angle: {int(left_angle)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "#         cv2.putText(img, f\"Right Hip Angle: {int(right_angle)}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "#         # 랜드마크 표시 (옵션)\n",
        "#         mp.solutions.drawing_utils.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "#     # 결과 이미지 표시\n",
        "#     cv2_imshow(img)\n",
        "\n",
        "#     # 'q'를 눌러 종료\n",
        "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         break\n"
      ],
      "metadata": {
        "id": "zMOqdYjjUx4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최종(test 필요)\n",
        "# 안됨 또 또 안됨\n",
        "# Posture 수정 피ㅣㄹ요\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# JavaScript로 웹캠 시작\n",
        "def start_video_stream():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.style.display = 'block';\n",
        "            document.body.append(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({\n",
        "                video: true\n",
        "            });\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            await new Promise((resolve) => {\n",
        "                video.onloadedmetadata = () => { resolve(video); };\n",
        "            });\n",
        "\n",
        "            video.play();\n",
        "            window.video = video;\n",
        "        }\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# 비디오 프레임을 가져오는 F (수정된 방식)\n",
        "def video_frame():\n",
        "    js = eval_js('''\n",
        "        const video = document.querySelector('video');\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        const context = canvas.getContext('2d');\n",
        "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "\n",
        "        window.canvasData = canvas.toDataURL('image/png');\n",
        "    ''')\n",
        "\n",
        "    return eval_js('window.canvasData')\n",
        "\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "\n",
        "    img_str = js_reply.split(',')[1]\n",
        "    try:\n",
        "        img_data = base64.b64decode(img_str)\n",
        "        img = Image.open(BytesIO(img_data))\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error decoding image: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# 허리 각도를 계산하는 함수\n",
        "def calculate_angle(a, b, c):\n",
        "\n",
        "    a = np.array([a.x, a.y])\n",
        "    b = np.array([b.x, b.y])\n",
        "    c = np.array([c.x, c.y])\n",
        "\n",
        "    # 두 벡터 간의 각도 계산 (단위: 라디안)\n",
        "\n",
        "    radians = np.arctan2(c[1]-b[1], c[0]-b[0])-np.arctan2(a[1]-b[1], a[0]-b[0])\n",
        "    angle = np.abs(radians*180.0/np.pi)\n",
        "    if angle > 180.0:\n",
        "      angle = 360 - angle\n",
        "    return angle\n",
        "\n",
        "def analyze_posture(upper_body_angle, neck_angle):\n",
        "  posture = \"좋음\"\n",
        "  if upper_body_angle < 170 or upper_body_angle > 190:\n",
        "    posture = \"나쁨 - 상체가 기울어져 있습니다.\"\n",
        "  elif neck_angle < 40 or neck_angle > 50:\n",
        "    posture = \"나쁨 - 목이 앞으로 굽어져 있습니다.\"\n",
        "  return posture                                      # -> 임의로 설정 수정 필요\n",
        "\n",
        "    # dot_product = np.dot(vector1, vector2)\n",
        "    # magnitude1 = np.linalg.norm(vector1)\n",
        "    # magnitude2 = np.linalg.norm(vector2)\n",
        "    # angle_rad = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
        "    # angle_deg = np.degrees(angle_rad)\n",
        "    # return angle_deg\n",
        "\n",
        "# 비디오 스트리밍 (+- 수정)\n",
        "start_video_stream()\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame()            # JavaScript로부터 비디오 프레임 받음\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    img = js_to_image(js_reply)               # 프레임을 OpenCV 이미지로 변환\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    # MediaPipe Pose로 사람의 자세 추적\n",
        "    results = pose.process(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "        # 상체기울기 계산\n",
        "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "        right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "\n",
        "        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "        right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "\n",
        "        shoulder = np.array([(left_shoulder.x + right_shoulder.x) / 2, (left_shoulder.y + right_shoulder.y) / 2])\n",
        "        hip = np.array([(left_hip.x + right_hip.x) / 2, (left_hip.y + right_hip.y) / 2])\n",
        "        upper_body_angle = calculate_angle(\n",
        "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
        "            landmarks[mp_pose.PoseLandmark.LEFT_HIP],\n",
        "            landmarks[mp_pose.PoseLandmark.LEFT_KNEE]\n",
        "        )\n",
        "        #목기울기 계산\n",
        "        left_ear = landmarks[mp_pose.PoseLandmark.LEFT_EAR]\n",
        "        neck_angle = calculate_angle(left_ear, left_shoulder, left_hip)\n",
        "        #자세분석\n",
        "        posture = analyze_posture(upper_body_angle, neck_angle)              ########### 수정 필요\n",
        "        #결과표시\n",
        "        cv2.putText(img, f\"Upper Body Angle: {int(upper_body_angle)}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,0), 2)\n",
        "        cv2.putText(img, f\"Neck Angle: {int(neck_angle)}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,0), 2)\n",
        "        cv2.putText(img, f\"Posture: {posture}\", (10,90), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2)              ###########  수정 필요\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # # 왼쪽 엉덩이, 왼쪽 무릎, 왼쪽 어깨\n",
        "        # left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "        # left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE]\n",
        "        # left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "\n",
        "        # # 오른쪽 엉덩이, 오른쪽 무릎, 오른쪽 어깨\n",
        "        # right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "        # right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE]\n",
        "        # right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "\n",
        "        # # 왼쪽과 오른쪽 허리 각도 계산\n",
        "        # left_angle = calculate_angle(left_hip, left_knee, left_shoulder)\n",
        "        # right_angle = calculate_angle(right_hip, right_knee, right_shoulder)\n",
        "\n",
        "        # # 각도를 텍스트로 화면에 출력\n",
        "        # cv2.putText(img, f\"Left Hip Angle: {int(left_angle)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        # cv2.putText(img, f\"Right Hip Angle: {int(right_angle)}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # 랜드마크 표시 (옵션)\n",
        "        mp.solutions.drawing_utils.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "\n",
        "    cv2_imshow(img)\n",
        "\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DGV9Wh1NgJo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 목까지 인식\n",
        "\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "# JavaScript로 웹캠 시작하기\n",
        "def start_video_stream():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.style.display = 'block';\n",
        "            document.body.append(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({\n",
        "                video: true\n",
        "            });\n",
        "            video.srcObject = stream;\n",
        "\n",
        "            await new Promise((resolve) => {\n",
        "                video.onloadedmetadata = () => { resolve(video); };\n",
        "            });\n",
        "\n",
        "            video.play();\n",
        "            window.video = video;\n",
        "        }\n",
        "        startVideo();\n",
        "    '''))\n",
        "\n",
        "# 비디오 프레임을 가져오는 함수\n",
        "def video_frame():\n",
        "    js = eval_js('''\n",
        "        const video = document.querySelector('video');\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        const context = canvas.getContext('2d');\n",
        "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "        window.canvasData = canvas.toDataURL('image/png');\n",
        "    ''')\n",
        "    return eval_js('window.canvasData')\n",
        "\n",
        "# JavaScript 응답을 OpenCV 이미지로 변환\n",
        "def js_to_image(js_reply):\n",
        "    img_str = js_reply.split(',')[1]\n",
        "    try:\n",
        "        img_data = base64.b64decode(img_str)\n",
        "        img = Image.open(BytesIO(img_data))\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error decoding image: {e}\")\n",
        "        return None\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# 각도 계산 함수\n",
        "def calculate_angle(a, b, c):\n",
        "    vector1 = np.array([a.x - b.x, a.y - b.y])\n",
        "    vector2 = np.array([c.x - b.x, c.y - b.y])\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    magnitude1 = np.linalg.norm(vector1)\n",
        "    magnitude2 = np.linalg.norm(vector2)\n",
        "    angle_rad = np.arccos(dot_product / (magnitude1 * magnitude2))\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "    return angle_deg\n",
        "\n",
        "# 비디오 스트리밍 시작\n",
        "start_video_stream()\n",
        "\n",
        "# 비디오 처리\n",
        "while True:\n",
        "    js_reply = video_frame()\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    img = js_to_image(js_reply)\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    results = pose.process(img)\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "        # 상체와 얼굴의 랜드마크\n",
        "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "        left_elbow = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW]\n",
        "        left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]\n",
        "        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "        left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE]\n",
        "        left_ankle = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE]\n",
        "\n",
        "        # 목의 랜드마크를 계산: 어깨, 목, 머리\n",
        "        left_ear = landmarks[mp_pose.PoseLandmark.LEFT_EAR]\n",
        "        left_eye = landmarks[mp_pose.PoseLandmark.LEFT_EYE]\n",
        "\n",
        "        # 상체 각도 계산 (왼쪽 어깨, 왼쪽 엉덩이, 왼쪽 무릎)\n",
        "        left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
        "        right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
        "\n",
        "        # 목 각도 계산 (어깨, 목, 머리)\n",
        "        left_shoulder_angle = calculate_angle(left_shoulder, left_ear, left_eye)\n",
        "\n",
        "        # 각도를 화면에 표시\n",
        "        cv2.putText(img, f\"Left Hip Angle: {int(left_hip_angle)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(img, f\"Right Hip Angle: {int(right_hip_angle)}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(img, f\"Left Shoulder Angle: {int(left_shoulder_angle)}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # 랜드마크 그리기\n",
        "        mp.solutions.drawing_utils.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # 결과 이미지 표시\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n"
      ],
      "metadata": {
        "id": "O6m8raJNZIVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import math\n",
        "\n",
        "# MediaPipe 포즈 모델 로드\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# 웹캠 비디오 캡처\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    # 각도 계산 함수\n",
        "    angle = math.degrees(math.atan2(c[1] - b[1], c[0] - b[0]) - math.atan2(a[1] - b[1], a[0] - b[0]))\n",
        "    if angle < 0:\n",
        "        angle += 360\n",
        "    return angle\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # BGR 이미지를 RGB로 변환\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 자세 인식\n",
        "    result = pose.process(rgb_frame)\n",
        "\n",
        "    # 키포인트 그리기\n",
        "    if result.pose_landmarks:\n",
        "        for landmark in result.pose_landmarks.landmark:\n",
        "            x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
        "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
        "\n",
        "        # 예시: 허리 각도 계산 (허리 부위 두 포인트를 이용)\n",
        "        left_hip = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "        right_hip = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "        shoulder = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "\n",
        "        # 허리 각도 계산\n",
        "        angle = calculate_angle([left_hip.x, left_hip.y], [shoulder.x, shoulder.y], [right_hip.x, right_hip.y])\n",
        "\n",
        "        # 각도 텍스트 표시\n",
        "        cv2.putText(frame, f'Angle: {angle:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # 화면에 결과 출력\n",
        "    cv2.imshow(\"Pose Estimation\", frame)\n",
        "\n",
        "    # 'q' 키를 눌러 종료\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# 종료 후 리소스 해제\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "uxMy5ZmpLXG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "def start_video_stream():\n",
        "    display(Javascript('''\n",
        "        async function startVideo() {\n",
        "            const video = document.createElement('video');\n",
        "            video.width = 640;\n",
        "            video.height = 480;\n",
        "            video.style.display = 'block';\n",
        "            document.body.append(video);\n",
        "\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({\n",
        "                video: true\n",
        "            });\n",
        "            video.srcObject = stream;\n",
        "            await new Promise((resolve) => {\n",
        "                video.onloadedmetadata = () => { resolve(video); };\n",
        "            });\n",
        "            video.play();\n",
        "            window.video = video;\n",
        "        }\n",
        "        startVideo();\n",
        "    '''))\n",
        "def video_frame():\n",
        "    js = eval_js('''\n",
        "        const video = document.querySelector('video');\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        const context = canvas.getContext('2d');\n",
        "        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "        window.canvasData = canvas.toDataURL('image/png');\n",
        "    ''')\n",
        "    return eval_js('window.canvasData')\n",
        "def js_to_image(js_reply):\n",
        "    img_str = js_reply.split(',')[1]\n",
        "    try:\n",
        "        img_data = base64.b64decode(img_str)\n",
        "        img = Image.open(BytesIO(img_data))\n",
        "        img = np.array(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error decoding image: {e}\")\n",
        "        return None\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "def calculate_angle(a, b, c):\n",
        "    a = np.array([a.x, a.y])\n",
        "    b = np.array([b.x, b.y])\n",
        "    c = np.array([c.x, c.y])\n",
        "    radians = np.arctan2(c[1]-b[1], c[0]-b[0])-np.arctan2(a[1]-b[1], a[0]-b[0])\n",
        "    angle = np.abs(radians*180.0/np.pi)\n",
        "    if angle > 180.0:\n",
        "      angle = 360 - angle\n",
        "    return angle\n",
        "def analyze_posture(upper_body_angle, neck_angle):\n",
        "  posture = \"좋음\"\n",
        "  if upper_body_angle < 170 or upper_body_angle > 190:\n",
        "    posture = \"나쁨 - 상체가 기울어져 있습니다.\"\n",
        "  elif neck_angle < 40 or neck_angle > 50:\n",
        "    posture = \"나쁨 - 목이 앞으로 굽어져 있습니다.\"\n",
        "  return posture\n",
        "start_video_stream()\n",
        "while True:\n",
        "    js_reply = video_frame()\n",
        "    if not js_reply:\n",
        "        break\n",
        "    img = js_to_image(js_reply)\n",
        "    if img is None:\n",
        "        continue\n",
        "    results = pose.process(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "    if results.pose_landmarks:\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
        "        right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
        "        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]\n",
        "        right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]\n",
        "        shoulder = np.array([(left_shoulder.x + right_shoulder.x) / 2, (left_shoulder.y + right_shoulder.y) / 2])\n",
        "        hip = np.array([(left_hip.x + right_hip.x) / 2, (left_hip.y + right_hip.y) / 2])\n",
        "        upper_body_angle = calculate_angle(\n",
        "            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
        "            landmarks[mp_pose.PoseLandmark.LEFT_HIP],\n",
        "            landmarks[mp_pose.PoseLandmark.LEFT_KNEE]\n",
        "        )\n",
        "        left_ear = landmarks[mp_pose.PoseLandmark.LEFT_EAR]\n",
        "        neck_angle = calculate_angle(left_ear, left_shoulder, left_hip)\n",
        "        posture = analyze_posture(upper_body_angle, neck_angle)\n",
        "        cv2.putText(img, f\"Upper Body Angle: {int(upper_body_angle)}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,0), 2)\n",
        "        cv2.putText(img, f\"Neck Angle: {int(neck_angle)}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255,0), 2)\n",
        "        cv2.putText(img, f\"Posture: {posture}\", (10,90), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0,255), 2)\n",
        "        mp.solutions.drawing_utils.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "    cv2_imshow(img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "2Q3woRoYC6EH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}